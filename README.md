# Stock Market Kafka Real Time Data Engineering Project

## Introduction 
This project demonstrates a real-time data pipeline to ingest stock market data using Apache Kafka, store the data in Amazon S3, and query it with AWS Athena after cataloging it with AWS Glue.The goal is to efficiently process and analyze stock market data through a well-defined workflow.



## Architecture 
<img src="Architecture.jpg">


## Technologies Used

- **Programming Language:** Python, SQL

- **Amazon Web Services (AWS):**
  - S3 (Simple Storage Service)
  - Athena
  - AWS Glue
    - Glue Crawler
    - Glue Catalog
  - Amazon EC2

- **Confluent Kafka**


## Workflow Overview ðŸ“Š

1. **Read data from CSV:**
   - Utilize Python to read stock market data from a CSV file, preparing it for further processing.

2. **Send it to Confluent Kafka with Avro schema:**
   - Leverage Confluent Kafka to efficiently stream the data with Avro schema for effective serialization.

3. **Consume, transform, and store individually in AWS S3 as JSON:**
   - Develop a consumer to process and transform the data, storing it individually in AWS S3 in JSON format.

4. **Glue Crawler does its magic, creating a data catalog:**
   - Employ AWS Glue Crawler to automatically discover and catalog the data in the S3 bucket, enhancing data management.

5. **Athena steps in, empowering me to query insights seamlessly:**
   - Utilize AWS Athena for effortless querying and gaining valuable insights from the processed data.

## Contribution 
Contributions are welcome! Please open an issue or submit a pull request for any improvements or new features.

## Contact :-
For any questions or feedback, please reach out to me at [Email](mailto:mdfurquan313@gmail.com) or connect with me on [LinkedIn](https://www.linkedin.com/in/mohammad-furquan-713561234/).

---

Check out my other projects at [GitHub](https://github.com/MohammadFurquan). </br>
Thank you!


